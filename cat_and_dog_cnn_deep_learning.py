# -*- coding: utf-8 -*-
"""Cat and Dog CNN DEEP LEARNING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WjfXEpzQmw4Fd9UFMJcHXbkLvNERY0nr
"""

!mkdir -p ~/.kaggle/
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d salader/dogs-vs-cats

import zipfile


zip_data = zipfile.ZipFile("/content/dogs-vs-cats.zip")
zip_data.extractall("/content/")
zip_data.close()

import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Conv2D , MaxPooling2D , Flatten , Dense
from keras.layers import Dropout ,BatchNormalization
from keras.preprocessing.image import ImageDataGenerator

import matplotlib.pyplot as plt
import cv2

img = plt.imread("/content/train/cats/cat.10016.jpg")

img

img = cv2.imread("/content/train/cats/cat.10016.jpg")

img

"""## **Gentraing The Dataset**"""

train_ds =tf.keras.preprocessing.image_dataset_from_directory(
    directory="/content/train",
    labels='inferred',
    label_mode='int',
    color_mode='rgb',
    batch_size=32,
    image_size=(256, 256),
    shuffle=True,
)
test_ds =tf.keras.preprocessing.image_dataset_from_directory(
    directory="/content/test",
    labels='inferred',
    label_mode='int',
    color_mode='rgb',
    batch_size=32,
    image_size=(256, 256),
    shuffle=True,
)

"""# **Data Augmentation Techinque**"""

#datagen = ImageDataGenerator(rotation_range=10,
                            # width_shift_range=0.1,
                           #  height_shift_range=0.1,
                            # zoom_range=0.1,
                             #horizontal_flip=True,
                             #vertical_flip=True,
                             #shear_range=0.1,
                             )
#Apply the Data augmnetation on Training Dataset

#train_ds=datagen.flow_from_directory(
 #   directory=("/content/train"),
 #  target_size=(256, 256),
 #   color_mode='rgb',
  #  class_mode='binary',
  #  batch_size=32,
  #  shuffle=True,

#)

def scale_down_px(image , label):
  image =  tf.cast(image/255 , tf.float32)

  return image , label

train_ds = train_ds.map(scale_down_px)
test_ds = test_ds.map(scale_down_px)

train_ds

test_ds

"""# **Creating The CNN Architecture**"""

model = Sequential()


model.add(Conv2D(32,kernel_size=(3,3),padding="valid",activation="relu",input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding="valid"))


model.add(Conv2D(32,kernel_size=(3,3),padding="valid",activation="relu",input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding="valid"))


model.add(Conv2D(32,kernel_size=(3,3),padding="valid",activation="relu",input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding="valid"))

model.add(Conv2D(32,kernel_size=(3,3),padding="valid",activation="relu",input_shape=(256,256,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding="valid"))


model.add(Flatten())


model.add(Dense(128,activation="relu"))
model.add(Dropout(0,1))
model.add(Dense(64,activation="relu"))
model.add(Dropout(0,1))
model.add(Dense(32,activation="relu"))
model.add(Dropout(0,1))
model.add(Dense(1,activation="sigmoid"))

model.summary()

model.compile(optimizer="adam",loss="binary_crossentropy",metrics="accuracy")

result = model.fit(train_ds,validation_data=test_ds, epochs=10)

"""# **Graph Measurement for Training And Validation Accuracy**"""

plt.plot(result.history["accuracy"],color="r",label="Training Accuracy",marker="o")
plt.plot(result.history["val_accuracy"],color="b",label="Validation Accuracy",marker="*")
plt.title("Line Plot Training and val Accuracy")
plt.xlabel("Number of Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""# **Graph Measurement for Training And Validation Loss**"""

plt.plot(result.history["loss"],color="r",label="Training Loss",marker="o")
plt.plot(result.history["val_loss"],color="b",label="Validation Loss",marker="o")
plt.title("Line Plot Training and val Accuracy")
plt.xlabel("Number of Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

"""# **Testing The Model**"""

def image_classifier(img_path):

    test_img = cv2.imread(img_path)
    print("Before Rezeing The Image",test_img.shape)
    test_img = cv2.resize(test_img,(256,256))
    print("After Rezeing The Image",test_img.shape)
    print("\n")
    test_input= test_img.reshape(1,256,256,3)
    output=model.predict(test_input)

    if output<=0.5:
      print("This is a Cat ")
    else:
      print("This is a Dog")

    print("\n")
    plt.imshow(test_img)

image_classifier("/content/test/dogs/dog.10022.jpg")
image_classifier()

image_classifier("/content/test/cats/cat.10033.jpg")

image_classifier("/content/Fluffy_White_Persian_Cat.jpg.webp")

image_classifier("/content/WhatsApp Image 2024-04-05 at 22.30.17_5c883868.jpg")

image_classifier("/content/WhatsApp Image 2024-04-05 at 23.00.36_a1b627aa.jpg")

image_classifier("/content/WhatsApp Image 2024-04-05 at 23.00.36_f0ee42ec.jpg")

image_classifier("/content/Blue-Nose-Pitbull-review.jpg")

image_classifier("/content/download.jpeg")



image_classifier("/content/images.jpeg")

image_classifier("/content/download (1).jpeg")

image_classifier("/content/images (1).jpeg")



















